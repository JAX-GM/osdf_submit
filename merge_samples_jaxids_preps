#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
File: merge_samples_jaxids_preps
Author: Benjamin Leopold
Date: 2016-08-05T12:59:11
Description: Tracks parents and children within jaxid hierarchy.
             Matches all sequence prep (dna, rna, 16s) with samples via jaxids.

Usage:
    track_jaxid_parents -l <jaxid_libaries.csv> -o outfile(stdout)

"""

# TODO: move from reference spreadsheet usage to direct jaxid_db checking

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Imports ~~~~~
from __future__ import print_function

import os
import re
import csv
import json
import yaml
import logging
import argparse
from collections import OrderedDict

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Constants ~~~~~
COOLNESS = True

class settings():
    """default values for  settings"""
    jaxid_ref_file = 'jaxid_database_export_20160801.csv'
    id_ref_map = None
    jaxid_sample_fieldname = 'jaxid_sample'
    jaxid_lib_fieldname = 'jaxid_library'
    parent_outfile = 'merged_parent_ids.csv'
    sample_outfile = 'merged_samples.csv'

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Functional ~~~~~

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~  Utility Functions  ~~~~~
# Log It!
def log_it(logname=os.path.basename(__file__)):
    import time
    """log_it setup"""
    curtime = time.strftime("%Y%m%d-%H%M")
    logfile = '{}_{}.log'.format(curtime, logname)

    loglevel = logging.INFO
    # logFormat="%(asctime)s %(levelname)5s: %(funcName)15s: %(message)s"
    logFormat="%(asctime)s %(levelname)5s: %(message)s"

    logging.basicConfig(format=logFormat)
    logger = logging.getLogger(logname)
    logger.setLevel(loglevel)

    fh = logging.FileHandler(logfile, mode='a')
    formatter = logging.Formatter(logFormat)
    fh.setFormatter(formatter)
    logger.addHandler(fh)
    return logger

log = log_it('track_jaxid_parents')


def get_field_header(csv_file):
    """returns first row of csv file as list of fieldnames"""
    log.info('Loading fieldnames from {}'.format(csv_file))
    with open(csv_file) as csvfh:
        try:
            reader = csv.DictReader(csvfh)
            log.debug("func: %s, fieldnames: %s", 'get_field_header',
                      str(reader.fieldnames))
            return reader.fieldnames
        except csv.Error as e:
            log.exception('Trying to read CSV file %s, line %d: %s',
                    csv_file, reader.line_num, e)


def load_data(csv_file):
    """yield row dicts from csv_file using DictReader
    """
    log.info('Loading rows from {}'.format(csv_file))
    with open(csv_file) as csvfh:
        reader = csv.DictReader(csvfh)
        # log.debug('csv dictreader opened')
        try:
            for row in reader:
                # log.debug(row)
                yield row
        except csv.Error as e:
            log.exception('Reading CSV file %s, line %d: %s',
                    csv_file, reader.line_num, e)


def write_out_csv(csv_file,fieldnames,values=[]):
    """write all values in csv format to outfile.
    Values is list of dicts w/ keys matching fieldnames.
    To write header to file, omit `values`
    """
    log.info('Writing CSV to {}'.format(csv_file))
    try:
        with open(csv_file, 'a') as csvout:
            writer = csv.DictWriter(csvout, fieldnames)
            if values:
                try:
                    for row in values:
                        if isinstance(row, dict):
                            log.debug('writerow: %s', str(row))
                            writer.writerow(row)
                except Exception, e:
                    log.exception('Writing CSV file %s, %s', csv_file, str(e))
                    raise e
            else:
                log.info('Writing header of fieldnames to {}'.format(csv_file))
                writer.writeheader()
    except IOError, e:
        func_name = 'write_out_csv'
        raise '{}: {}'.format(func_name, str(e))

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~   Local Functions   ~~~~~

def get_parent_node_id(ref_map, jaxid, parent_id):
    """ read node ids from csv tracking file
        return first "parent" node matching node_type
    """
    log.debug("in function: %s", 'get_parent_node_id')
    log.debug('--> args: '+ id_file_name +','+ node_type +','+ parent_id)
    try:
        pass
        # for row in load_data(id_file_name):
            # if re.match(node_type.lower(),row['node_type']):
                # if row['jaxid']:
                    # log.debug('--> matching node row: '+ str(row))
                    # return row['parent_id']
                # else:
                    # log.debug('--> no match node row for: '+ str(parent_id))
            # else:
                # log.debug('--> no match node row: '+ str(node_type))
    except Exception, e:
        func_name = 'get_parent_node_id'
        raise '{}: {}'.format(func_name, str(e))


def get_child_node_ids(id_file_name, node_type, parent_id):
    """ read node ids from csv tracking file
        yield "child" node ids matching node_type
    """
    log.debug("in function: %s", 'get_child_node_id')
    try:
        for row in load_data(id_file_name):
            if re.match(node_type,row['node_type']):
                if re.match(parent_id,row['internal_id']):
                    log.debug('--> matching node row: '+ str(row))
                    log.debug('parent type: {}, osdf_node_id: {}'.format(
                        node_type,str(row['osdf_node_id'])))
                    return row['osdf_node_id']
    except Exception, e:
        func_name = 'get_child_node_id'
        raise '{}: {}'.format(func_name, str(e))


def build_id_ref_map(ref_in):
    """construct reference mapping dict of ids from csv file"""
    log.debug("in function: %s", 'build_id_ref_map')
    ref_map = {}
    for row in load_data(ref_in):
        ref_map[row['jaxid']] = row
    log.debug("finished function: %s", 'build_id_ref_map')
    return ref_map


def which_id_type(record_dict):
    """determine which id type is being parsed"""
    # log.debug("in function: %s", 'which_id_type')
    # spreadsheet logic:
    #   =IF(NOT(ISERROR(search("pool",D73))),"pool",
    #       IF(AND(F73="Z",G73="Z",H73="Z"),"NULL",
    #           IF(and(G73="Z",H73="Z"),"specimen",
    #              IF(H73="Z","extraction",
    #                         "library")
    #           )
    #         )
    #      )
    # log.debug("in function: %s", 'which_id_type')
    try:
        idtype = ''

        collab = record_dict['collab_id']
        sample = record_dict['sample']
        nucleic = record_dict['nucleic_acid']
        seqtype = record_dict['seq_type']

        if re.search('pool', collab):
            idtype = 'pool'
        elif sample == 'Z':
            idtype = 'NULL' # bad!!!
        elif nucleic == 'Z':
            idtype = 'specimen'
        elif seqtype == 'Z':
            idtype = 'extraction'
        else:
            idtype = 'library'
        # log.debug("function: %s, idtype==%s", 'which_id_type', idtype)
        return idtype
    except Exception, e:
        # raise e
        # log.error("function: %s, idtype==%s", 'which_id_type', idtype)
        return ''


def which_parent_type(id_type):
    """Goes up the hierarchical list of types
       returning the direct parent type.
    """
    log.debug("in function: %s", 'which_parent_type')
    id_list = [
                None,
                'specimen',
                'extraction',
                'library',
               ]
    family_tree = {
            id_list[t-1]:id_list[t]
            for t in id_list
            if t > 0
            }
    return family_tree[id_type]


def get_received_id(idrow):
    """use get_parent_id to track recursively to original sample received"""
    log.debug("in function: %s", 'get_received_id')
    # fieldnames = ['jaxid', 'parent_id']
    try:
        parent_id = idrow['parent_id']
        if parent_id == 'received':
            return idrow['jaxid']
        elif parent_id in settings.id_ref_map:
            return get_received_id(settings.id_ref_map[parent_id])
        else:
            return ''

    except Exception, e:
        func_name = 'get_received_id'
        raise '{}: {}'.format(func_name, str(e))


def track_library_parents(library_csv, outfile):
    """Incoming: csv file with library jaxids
       Outgoing: csv outfile with new column 'jaxid_parent'
       Uses the 'settings.jaxid_ref_file' as mapping source.
       Return: parent_id_map of all updated rows, for later use
    """
    log.debug("in function: %s", 'track_library_parents')
    jaxid_lib = settings.jaxid_lib_fieldname
    outfile = sample_list_in+'_merged.csv'
    outfields = get_field_header(library_csv)
    outfields.insert(outfields.index(
                     settings.jaxid_lib_fieldname)+1,
                     'jaxid_parent')
    write_out_csv(outfile, outfields) # field headers

    parent_id_map = {}
    for row in load_data(library_csv):
        try:
            row['jaxid_parent'] = ''
            if row[jaxid_lib] in settings.id_ref_map:
                idrow = settings.id_ref_map.get(row[jaxid_lib])
                idtype = which_id_type(idrow)
                if not idtype:  # just in case there are not fields in idrow
                    idtype = 'library'
                try:
                    row['jaxid_parent'] = get_received_id(idrow)
                except Exception, e:
                    raise e
        except Exception, e:
            func_name = 'track_library_parents'
            raise '{}: {}'.format(func_name, str(e))
        write_out_csv(outfile, outfields, [row])
        parent_id_map[row['jaxid_parent']] = row
        # log.debug("parent_id_map row: ")
        # log.debug(row)

    # log.debug('parent_id_map: %s', str(parent_id_map))
    log.debug("done function: %s", 'track_library_parents')
    return parent_id_map


def merge_library_prep_ids_w_sample_list(sample_list_in,
                                         parent_outfile,
                                         parent_id_map):
    """Usage: for seqprep rows with library jaxids matching to received ids
              with the list of samples nodes.
       Intent: create sheets of [dr]naprep node metadata.
       Tactic: Use double-for loop in each of samples and parent_id_map
    """
    log.debug("Begin function: %s", 'merge_library_prep_ids_w_sample_list')
    jaxid_sample_fieldname = settings.jaxid_sample_fieldname
    outfile = sample_list_in+'_merged.csv'
    outfields = get_field_header(sample_list_in)
    # log.debug("func: %s, fieldnames: %s", 'merge_library_prep...'
    #           str(outfields))
    # outfields.extend(get_field_header(args.library_csv))
    pv = parent_id_map.itervalues()
    outfields.extend(pv.next())
    log.debug("func: %s, fieldnames: %s", 'merge_library_prep...',
              str(outfields))
    write_out_csv(outfile, outfields) # field headers

    # sample_id_map = {}
    for srow in load_data(sample_list_in):
        # log.debug("in function: %s, row: %s", 'merge_library_prep...', srow)
        try:
            jaxid_sample = srow.get(jaxid_sample_fieldname)
            if jaxid_sample:
                log.debug("function: %s, jaxid_sample: %s",
                          'merge_library_prep...',
                          jaxid_sample)
                if jaxid_sample in parent_id_map:
                    log.debug('function: %s, items: %s',
                              'merge_library_prep...',
                              parent_id_map[jaxid_sample])
                    sampleidvals = srow.update(
                                               dict(parent_id_map[jaxid_sample]))
                    log.debug('function: %s, idvals: %s',
                              'merge_library_prep...',
                              str(sampleidvals)
                             )
                    write_out_csv(outfile, outfields, [sampleidvals])
            else:
                write_out_csv(outfile, outfields, [srow])

        except Exception, e:
            func_name = 'merge_library_prep_ids_w_sample_list'
            raise '{}: {}'.format(func_name, str(e))

    log.debug("done function: %s", 'merge_library_prep_ids_w_sample_list')
    return True


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Make it happen! ~~~~~

def parse_args(args):
    """all args to script are parsed here"""
    #TODO: add inbound/outbound streams, not files (read/write csv and/or sql)
    parser = argparse.ArgumentParser()
    add = parser.add_argument

    # add('-j', '--jaxid_lib_fieldname',
    #     metavar='JAXID_LIB_FIELDNAME', default=settings,jaxid_lib_fieldname,
    #     help="field name of beginning jaxid column {}".format(
    #           settings.jaxid_lib_fieldname))
    add('-l', '--library_csv',
        metavar='LIBRARY_CSV', default=None,
        help="CSV File containing column {}".format(settings.jaxid_lib_fieldname))
    add('-s', '--sample_sheet',  ## requires library_csv!!
        metavar='SAMPLE_CSV', default=None,
        help="CSV File containing column {}".format(settings.jaxid_sample_fieldname))
    add('-o', '--outfile',
        metavar='OUTFILE', default=settings.parent_outfile,
        # type=argparse.FileType('a'),
        help='File to store output') # (default stdout)')
    add("-r", "--jaxid_ref_file",
        metavar='JAXID_REF_FILE',
        default=settings.jaxid_ref_file,
        dest='ref_file',
        help="jaxid relation reference spreadsheet")
    add("-v", "--verbose",
        default=False,
        action="store_true",
        help="increase output verbosity")
    return parser.parse_args(args)


def main(args):
    """get it done!"""
    success = False
    try:
        if args.verbose:
            log.setLevel(logging.DEBUG)

        # ref_file = settings.jaxid_ref_file
        if os.access(args.ref_file, os.R_OK):
            settings.id_ref_map = build_id_ref_map(args.ref_file)
        else:
            log.error("JAXid reference file is not readable or doesn't exist!")
            return False

        if args.library_csv:
            parent_id_map = track_library_parents(args.library_csv,
                                                   args.outfile)
            success = True

            if args.sample_sheet:
                success = merge_library_prep_ids_w_sample_list(
                                    args.sample_sheet,
                                    args.outfile,
                                    parent_id_map)

    except Exception, e:
        raise e

    return success


if __name__ == '__main__':
    import sys
    # args = parse_args('-v -l test_jaxid_libs.csv'.split())
    args = parse_args(sys.argv[1:])
    sys.exit(main(args))

#  vim: set ft=python ts=4 sw=4 tw=79 et :
